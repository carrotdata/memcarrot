#################################################################################
# Memcarrot configuration
################################################################################
#
# Server port
server.port=11211

#
# Server host
server.address=localhost

#
# Worker pool size
#workers.pool.size=1
workers.pool.size=8

#
# I/O buffer size
#kv.size.max=4194304
#

# TCP Send/Receive buffer size
#
#tcp.buffer.size=32768
tcp.buffer.size=8192

#################################################################################
#  Carrot Cache configuration file
#################################################################################

#
# List of all caches logical names, comma-separated
#
#cache.names=cache
cache.names=L1

#
# Caches types ('memory', 'file' only supported), comma-separated
#
cache.types=memory

# 
#  Cache root directory - where to save cached data and snapshot
#
#root.dir.path=./data

#   
# Data segment size 
# Default is 4MB (Memory)
L1.data.segment.size=16m
# 
# Maximum storage limit to use for cache 
# Default - 1GB
L1.storage.size.max=60g

# 
# When to start GC (garbage collection) - size of the cache as a fraction of the maximum cache size 
#
#scavenger.ratio.start=0.99

#
# When to stop GC (garbage collection) - size of the cache as a fraction of the maximum cache size
#
#scavenger.ratio.stop=0.9

# 
# Discard cached entry if it in this lower percentile - start value (minimum)
#
#scavenger.dump.entry.below.min=0.1

#
# Discard cached entry if it in this lower percentile - stop value (maximum) 
#
scavenger.dump.entry.below.max=0.2

#
# Scavenger number of threads, increase this number if you have heavy writes
#
scavenger.number.threads=2

#
# Number of popularity ranks (or bins to insert incoming writes to)
#
#popularity.number.ranks=8

#
# Minimum active data set ratio
# When vacuum mode is on, this parameter controls the goal for 
# a periodic vacuum process - minimum ratio of active to a total objects 
#
#active.dataset.ratio.min=0.9

#
# IO Pool size for FileIO save segments to disk
#
#storage.io.pool.size=4

# 
# Number of segments in S-LRU (Eviction)  do not change it
#
#eviction.slru.number.segments=8

# 
# New item insertion point for SLRU (Eviction)
# Value between 0 and eviction.slru.number.segments - 1
#eviction.slru.insert.point=7

#
# Admission Queue start size in fraction of a full cache size
#
#admission.queue.size.ratio.start=0.5

# 
# Admission Queue minimum size in fraction of a full cache size
#
#admission.queue.size.ratio.min=0.1

# 
# Admission Queue maximum size in fraction of a full cache size
#
#admission.queue.size.ratio.max=0.5

#
# Promotion Queue start size in fraction of a full cache size
#
#promotion.queue.size.ratio.start=0.5

#
# Promotion Queue minimum size in fraction of a full cache size
#
#promotion.queue.size.ratio.min=0.1

#
# Promotion Queue maximum size in fraction of a full cache size
#
#promotion.queue.size.ratio.max=0.5

  
#
# Initial size of the MemoryIndex hash table, i.e size= 2**valueOf('index.slots.power')
# Default: 16 - 64K slots (2**16). To reduce objects collision probability keep this 
# number close to the maximum for your application. Let us say, that you estimate for 
# maximum number of objects in the cache is 100M. Your maximum size for the memory index
# hash table is 100M/200 = 0.5M and maximum value for this configuration option is log2(0.5M) ~ 20
# 
index.slots.power=23

#
# Promote item from victim cache on hit. 
# This setting controls whether we allow objects to be inserted from a victim 
# back to a parent cache
#  
#victim.promotion.on.hit=true

#
# Victim cache promotion popularity threshold. Only objects which popularity is above 90%
# will be promoted back to a parent cache
victim.promotion.threshold=0.95

#
# Cache write throughput check interval key  
#
#throughput.check.interval.sec=3600
  
#
# Cache write throughput controller tolerance limit
#
#throughput.tolerance.limit=0.05
  
#
# Throughput controller number of adjustment steps
#
#throughput.adjustment.steps=10


#####################    Plug-able API     
#
# Class name for main queue index format implementation
# BaseIndexFormat costs 20 bytes of RAM per object
# There are several formats to choose from whose RAM overhead ranges between 6 and 20 bytes
# The most optimal for performance-size are:
# index.format.impl=com.carrotdata.cache.index.SuperCompactBaseNoSizeWithExpireIndexFormat - 11 bytes per object
# index.format.impl=com.carrotdata.cache.index.SubCompactBaseNoSizeWithExpireIndexFormat - 12 bytes per object overhead
#
#index.format.impl=com.carrotdata.cache.index.BaseIndexFormat
index.format.impl=com.carrotdata.cache.index.SuperCompactBaseNoSizeWithExpireIndexFormat  

#
# Class name for cache eviction policy implementation
#
#eviction.policy.impl=com.carrotdata.cache.eviction.SLRUEvictionPolicy
  
#
# Class name for cache admission controller implementation (no default)
#
#admission.controller.impl=com.carrotdata.cache.controllers.ExpirationAwareAdmissionController

#
# For expiration based admission controller - minimum expiration time supported in seconds
#
#expire.bin.value.start=60
  
#
# For expiration  based admission controller - bin value multiplier
# Number of bins or buffers is defined by popularity.number.ranks, which is 8 by default
# Bear in mind that although increasing this number may help increase performance
# of a Scavenger (Garbage Colector) it increases overall memory usage as since each 
# bin (write buffer) has size of a data segment size (4MB, by default)
# With all default values we have 8 bins (write buffers), 60 sec limit for the first bin and 
# all subsequent bins will have 60 * 2, 60 * 4, 60 * 8, ... 60 * 128 limits
# So, all objects whose expiration time 60 sec or less will go to bin 0, less than 120 sec, 
# but greater than 60 - to bin 1, less than 240 s, but greater than 120 s - bin 2 etc.
# The major idea is to accumulate objects with a similar expiration times together (in the same data segments)
# This 
#expire.multiplier.value=2

#
# Class name for cache promotion controller implementation (no default)
#
#promotion.controller.impl=

#
# Class name for cache throughput controller implementation (no default)
#
#throughput.controller.impl=
  
#
# Class name for cache recycling controller implementation (used by Scavenger). Default implementation
# chooses data segments based on its proportion of an active objects - 
# those with the smallest ones come first. Another good option - 
# com.carrotdata.cache.controllers.LRCRecyclingSelector - Least Recently Created
#
recycling.selector.impl=com.carrotdata.cache.controllers.MinAliveRecyclingSelector
  
#
# Class name for cache data writer implementation.  
# This is for caches without compression support. 
# When compression is enabled this will be set automatically
# Another option to try - com.carrotdata.cache.io.BaseBatchDataWriter,
# which provides better write performance 
#data.writer.impl=com.carrotdata.cache.io.BaseDataWriter
  
#
# Class name for cache data reader implementation (Memory) - do not change it
# This is for caches without compression support.
# When compression is enabled this will be set automatically
#memory.data.reader.impl=com.carrotdata.cache.io.BaseMemoryDataReader
  
#
# Class name for cache data reader implementation (File) - do not change it
# unless you provide your own implementation
# This is for caches without compression support
# When compression is enabled this will be set automatically
#file.data.reader.impl=com.carrotdata.cache.io.BaseFileDataReader
  
#
# Block writer block size - used by BaseBatchDataWriter
#
#block.writer.block.size=4096
  
#
# File prefetch buffer size - Scavenger scanner's setting
#
#file.prefetch.buffer.size=4194304
  
#
# Cache expiration support implementation 
# supports range 1 sec - ~ 32678 (2^15) min
# Another option - com.carrotdata.cache.expire.ExpireSupportSecondsMinutesHours,
# which supports range 1s - ~ 16K hours (2^14), but it is still EXPERIMENTAL
#
#expire.support.impl=com.carrotdata.cache.expire.ExpireSupportSecondsMinutes

#
# JMX metrics domain name
#jmx.metrics.domain.name=com.carrotdata.cache

#
# Maximum wait time for put operation in ms
#
#cache.wait.put.max.ms=20

#
# Maximum key-value size (limited by data segment size as well)
#
#cache.max.kv.size = 268435448

#
# Maximum buffer size for thread local storage
#
#tls.buffer.size.max=268435456

############################
# Compression configuration
############################

#
# Cache compression enabled
#
compression.enabled=true

#
# Compression block size
#
compression.block.size=4096

#
# Compression dictionary size
# Usually the bigger - the better, but not always
#compression.dictionary.size=65536 (default)
compression.dictionary.size=1048576

#
# Compression level (-1-22 for ZSTD)
# Recommended options: -1 (faster) and 3 (still fast, compression is better)
# There is no need to go below -1 (this will be covered in a future by LZ4 codec,
# which have comparabale compression ratios but better speed)
#
compression.level=3

#
# Compression codec
#
#compression.codec=ZSTD

#
# Compression dictionary enabled
#
compression.dictionary.enabled=true

#
# Train dictionary on keys as well?
#
compression.keys.enabled=true

#
# Save cache on process shutdown.
# Disabled, by default. Enable it if you want to have
# a warm cache restarts
#
save.on.shutdown=true

#
# Estimated average key-value size in bytes. If you have good estimate
# for this value you can change it. This allows cache runtime to better 
# adjust its parameters.
#
#estimated.avg.kv.size=10240
estimated.avg.kv.size=1024

#
# Memory buffer pool size. You can save some memory by reducing this number
#
#memory.buffer.pool.size.max=4

#
# Pro-active expiration check probability (0-1) defines how 
# aggresevely CC scans memory index memory slots for expired objects during regular
# read operations. The large value the more aggresevely it will scan, but read perforamance
# can suffer a bit
# 
#proactive.expiration.factor=0.25

# 
# Object Cache initial output buffer size - not relevant for server
#  
#objectcache.buffer.size.start=64536

#
# Object Cache maximum output buffer size - not relevant for server
#
#objectcache.buffer.size.max=-1

#
# Vacuum cleaner interval in seconds
# Default: -1 - disabled
# For memcarrot we set it 60 seconds
#vacuum.cleaner.interval=60

#
# Evict all objects to victim cache. When object gets evicted from a parent cache
# it will be written into a victim cache only if its hits count is greater than 0
# - this is the default behaviour. You can disable this check and evict all objects into a victim cache
# this can make sense if :
# 1. Eviction rate is not very high 
# 2. Victim Cache (SSD) is large
# 3. Victim Cache has efficiently FIFO eviction policy
#victim.evict.all=false
